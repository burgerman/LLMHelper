spring.application.name=LLMHelper
# Logging configuration
logging.level.root=INFO
logging.level.com.burgerman.llmhelper=DEBUG
# Ollama API configuration
langchain4j.ollama.chat-model.base-url=http://localhost:11434/
langchain4j.ollama.chat-model.model-name=gemma3:4b
langchain4j.ollama.embedding-model.embedding-model-name=nomic-embed-text
langchain4j.ollama.chat-model.timeout=90
langchain4j.ollama.chat-model.max_response_length=1000